{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np #This works with numbers\n",
    "import pandas as pd #This allows us to work with a dataset\n",
    "import matplotlib.pyplot as plt #This allows us to plot data\n",
    "from sklearn.model_selection import train_test_split #For splitting data for training and test\n",
    "from sklearn.preprocessing import StandardScaler #For scaling features\n",
    "from sklearn import datasets, svm \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #For metrics and evaluation algorithm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier #For KNN\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import tree\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#--- Loading Data and dropping features\n",
    "#load data into dataframe\n",
    "data = pd.read_csv('HCV-Egy-Data.csv')\n",
    "\n",
    "# Remove Outliers \n",
    "X = data\n",
    "col = list(X.drop('Baselinehistological staging',axis=1).columns)\n",
    "for i in col:\n",
    "    y = data[i]\n",
    "    removed_outliers = y.between(y.quantile(.02), y.quantile(.98))\n",
    "    index_names = data[~removed_outliers].index \n",
    "    data.drop(index_names, inplace=True)\n",
    "    \n",
    "#dropping histoligical baseline due to duplicate representation of data\n",
    "data = data.drop('Baseline histological Grading', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#--- Descritization (Robert)\n",
    "\n",
    "#list of columns for binning\n",
    "weeks_list = ['AST 1', 'ALT 1', 'ALT4', 'ALT 12', 'ALT 24', 'ALT 36', 'ALT 48', 'ALT after 24 w']\n",
    "\n",
    "#descritizes the columns listed in weeks_list #sources: https://dfrieds.com/data-analysis/bin-values-python-pandas.html , https://stackoverflow.com/questions/48248731/pandas-cut-multiple-columns\n",
    "for feature in weeks_list:\n",
    "    data[feature] = pd.cut(x=data[feature], bins=[0,20,40,128], labels=[1,2,3]) #discrete values    \n",
    "\n",
    "#customized binning for the following features    \n",
    "#data['Age '] = pd.cut(x=data['Age '], bins=[0,32,37,42,47,52,57,62], labels=[1,2,3,4,5,6,7])\n",
    "data['BMI'] = pd.cut(x=data['BMI'], bins=[0,18.5,25,30,35,40], labels=[1,2,3,4,5])\n",
    "data['WBC'] = pd.cut(x=data['WBC'], bins=[0,4000,11000,12101], labels=[1,2,3])\n",
    "data['RBC'] = pd.cut(x=data['RBC'], bins=[0,3000000,5000000,5018451], labels=[1,2,3])\n",
    "#data['Plat'] = pd.cut(x=data['Plat'], bins=[93013,100000,226465], labels=[1,2]) #removed a typo discrete value of 255000\n",
    "data['RNA Base'] = pd.cut(x=data['RNA Base'], bins=[0,5,1201086], labels=[1,2])                                        \n",
    "data['RNA 4'] = pd.cut(x=data['RNA 4'], bins=[0,5,1201715], labels=[1,2])    \n",
    "data['RNA 12'] = pd.cut(x=data['RNA 12'], bins=[0,5,3731527], labels=[1,2])    \n",
    "data['RNA EOT'] = pd.cut(x=data['RNA EOT'], bins=[0,5,808450], labels=[1,2])    \n",
    "data['RNA EF'] = pd.cut(x=data['RNA EF'], bins=[0,5,810333], labels=[1,2])    # corrected maximum from 808450 in discretization description\n",
    "\n",
    "# conditional binning for HGB by Gender. Each gender row is placed in a gender conditional dataframe\n",
    "male_df = data[data['Gender']==1]\n",
    "male_df['HGB'] = pd.cut(x=male_df['HGB'], bins=[2,14,17.5,20], labels=[1,2,3])\n",
    "#print(male_df)\n",
    "female_df = data[data['Gender']==2]\n",
    "female_df['HGB'] = pd.cut(x=female_df['HGB'], bins=[2,12.3,15.3,20], labels=[1,2,3])\n",
    "#print(female_df)\n",
    "#merges male and female selections into a new dataframe\n",
    "data = pd.merge(male_df, female_df, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                                   int64\n",
       "Gender                                int64\n",
       "BMI                                   int64\n",
       "Fever                                 int64\n",
       "Nausea/Vomting                        int64\n",
       "Headache                              int64\n",
       "Diarrhea                              int64\n",
       "Fatigue & generalized bone ache       int64\n",
       "Jaundice                              int64\n",
       "Epigastric pain                       int64\n",
       "WBC                                   int64\n",
       "RBC                                   int64\n",
       "HGB                                   int64\n",
       "Plat                                float64\n",
       "AST 1                                 int64\n",
       "ALT 1                                 int64\n",
       "ALT4                                  int64\n",
       "ALT 12                                int64\n",
       "ALT 24                                int64\n",
       "ALT 36                                int64\n",
       "ALT 48                                int64\n",
       "ALT after 24 w                        int64\n",
       "RNA Base                              int64\n",
       "RNA 4                                 int64\n",
       "RNA 12                                int64\n",
       "RNA EOT                               int64\n",
       "RNA EF                                int64\n",
       "Baselinehistological staging          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# converting all datatypes to float (Robert)\n",
    "# source: https://stackoverflow.com/questions/44369504/how-to-convert-entire-dataframe-values-to-float-in-pandas\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>BMI</th>\n",
       "      <th>ALT 1</th>\n",
       "      <th>ALT4</th>\n",
       "      <th>ALT 24</th>\n",
       "      <th>ALT 48</th>\n",
       "      <th>AST 1</th>\n",
       "      <th>fib4</th>\n",
       "      <th>modapri</th>\n",
       "      <th>liverDam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000794</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000417</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000672</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000535</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000509</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>59</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>851</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000716</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>852</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000388</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>853</td>\n",
       "      <td>47</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>854</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>855 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Age   Gender  BMI  ALT 1  ALT4  ALT 24  ALT 48  AST 1      fib4  \\\n",
       "0      45       1    3      3     3       3       3      3  0.000794   \n",
       "1      34       1    2      3     3       3       3      3  0.000417   \n",
       "2      58       1    4      3     3       3       3      3  0.000672   \n",
       "3      61       1    4      3     3       3       3      3  0.000535   \n",
       "4      56       1    3      3     3       3       3      3  0.000509   \n",
       "..    ...     ...  ...    ...   ...     ...     ...    ...       ...   \n",
       "850    59       2    4      3     3       3       3      3  0.000959   \n",
       "851    43       2    2      3     3       3       3      3  0.000716   \n",
       "852    36       2    4      3     3       3       3      3  0.000388   \n",
       "853    47       2    4      3     3       3       3      3  0.000498   \n",
       "854    52       2    2      3     3       3       3      3  0.000492   \n",
       "\n",
       "      modapri  liverDam  \n",
       "0    0.000014       1.0  \n",
       "1    0.000007       1.0  \n",
       "2    0.000012       1.0  \n",
       "3    0.000009       1.0  \n",
       "4    0.000009       1.0  \n",
       "..        ...       ...  \n",
       "850  0.000017       1.0  \n",
       "851  0.000012       1.0  \n",
       "852  0.000007       1.0  \n",
       "853  0.000009       1.0  \n",
       "854  0.000009       1.0  \n",
       "\n",
       "[855 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    \n",
    "#seperate X and y\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "#Calculate biomarker scores\n",
    "fib4 = (X['Age ']*X['AST 1'])/(X['Plat']*np.sqrt(X['ALT 1']))\n",
    "modapri = (X['Age ']*X['AST 1'])/(X['Plat']*100)\n",
    "liverDam = X['AST 1']/X['ALT 1']\n",
    "\n",
    "#Feature selection Age, Gender, BMI\n",
    "ModX = X.iloc[:,0:3]\n",
    "\n",
    "#Select ALT scores over time\n",
    "ModX['ALT 1'] = X['ALT 1']\n",
    "ModX['ALT4'] = X['ALT4']\n",
    "ModX['ALT 24'] = X['ALT 24']\n",
    "ModX['ALT 48'] = X['ALT 48']\n",
    "\n",
    "ModX['AST 1'] = X['AST 1']\n",
    "\n",
    "ModX['fib4'] = fib4\n",
    "ModX['modapri'] = modapri\n",
    "ModX['liverDam'] = liverDam\n",
    "\n",
    "ModX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(ModX, y, test_size = 0.20, random_state = 0)\n",
    "\n",
    "#Feature scale so that one feature doesn't have more influence than another\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27536232 0.1884058  0.24637681 0.26086957 0.27536232 0.36764706\n",
      " 0.27941176 0.25       0.25       0.23880597]\n",
      "0.2632241605272868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#Here we are going to make a simple SVM classifier\n",
    "classifier = svm.NuSVC(nu = 0.3, kernel='rbf')\n",
    "#Carry out cross validation 10 fold and find the mean of the score to get overall accuracy for train data\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=10)\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34210526315789475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#train the classifier on train set and then print out its overall accuracy for the train data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24561403508771928\n"
     ]
    }
   ],
   "source": [
    "#Determine the overall accuracy score of the test data set\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      "[[16 13  7  8]\n",
      " [10 10 11  4]\n",
      " [21 11 10  4]\n",
      " [14 14 12  6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.26      0.36      0.30        44\n",
      "           2       0.21      0.29      0.24        35\n",
      "           3       0.25      0.22      0.23        46\n",
      "           4       0.27      0.13      0.18        46\n",
      "\n",
      "    accuracy                           0.25       171\n",
      "   macro avg       0.25      0.25      0.24       171\n",
      "weighted avg       0.25      0.25      0.24       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Making predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      "[[ 6  7 17 14]\n",
      " [ 8  6 15  6]\n",
      " [12  8 13 13]\n",
      " [12  9 16  9]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.16      0.14      0.15        44\n",
      "           2       0.20      0.17      0.18        35\n",
      "           3       0.21      0.28      0.24        46\n",
      "           4       0.21      0.20      0.20        46\n",
      "\n",
      "    accuracy                           0.20       171\n",
      "   macro avg       0.20      0.20      0.19       171\n",
      "weighted avg       0.20      0.20      0.20       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training with k-nearest neighbor (KNN)\n",
    "classifier2 = KNeighborsClassifier(n_neighbors = 100)\n",
    "classifier2.fit(X_train, y_train)\n",
    "#Making predictions\n",
    "y_pred = classifier2.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.24561403508771928\n",
      "The confusion matrix is:\n",
      "[[11 15  7 11]\n",
      " [ 8  5  7 15]\n",
      " [14  6 12 14]\n",
      " [15 10  7 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.23      0.25      0.24        44\n",
      "           2       0.14      0.14      0.14        35\n",
      "           3       0.36      0.26      0.30        46\n",
      "           4       0.26      0.30      0.28        46\n",
      "\n",
      "    accuracy                           0.25       171\n",
      "   macro avg       0.25      0.24      0.24       171\n",
      "weighted avg       0.25      0.25      0.25       171\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision trees\n",
    "#Here we are going to make a simple decision classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "#Determine the overall accuracy score of the test data set\n",
    "print(clf.score(X_test,y_test))\n",
    "#Making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
