{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import necessary libraries\n",
    "import numpy as np #This works with numbers\n",
    "import pandas as pd #This allows us to work with a dataset\n",
    "import matplotlib.pyplot as plt #This allows us to plot data\n",
    "from sklearn.model_selection import train_test_split #For splitting data for training and test\n",
    "from sklearn.preprocessing import StandardScaler #For scaling features\n",
    "from sklearn import datasets, svm \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score #For metrics and evaluation algorithm\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier #For KNN\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data into dataframe\n",
    "data = pd.read_csv('HCV-Egy-Data.csv')\n",
    "\n",
    "#dropping histoligical baseline due to duplicate representation of data  ## I don't want to drop the outliers (Robert)\n",
    "#data = data.drop('Baseline histological Grading', axis = 1)\n",
    "\n",
    "# Remove Outliers ## I don't want to drop the outliers (Robert)\n",
    "\n",
    "\n",
    "X = data\n",
    "col = list(X.drop('Baselinehistological staging',axis=1).columns)\n",
    "for i in col:\n",
    "    y = data[i]\n",
    "    removed_outliers = y.between(y.quantile(.02), y.quantile(.98))\n",
    "    index_names = data[~removed_outliers].index \n",
    "    data.drop(index_names, inplace=True)\n",
    "\n",
    "\n",
    "#dropping histoligical baseline due to duplicate representation of data, and it seems to decrease accuracy if included\n",
    "data = data.drop('Baseline histological Grading', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:25: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "#--- Descritization (Robert)\n",
    "\n",
    "#list of columns for binning\n",
    "weeks_list = ['AST 1', 'ALT 1', 'ALT4', 'ALT 12', 'ALT 24', 'ALT 36', 'ALT 48', 'ALT after 24 w']\n",
    "\n",
    "#descritizes the columns listed in weeks_list #sources: https://dfrieds.com/data-analysis/bin-values-python-pandas.html , https://stackoverflow.com/questions/48248731/pandas-cut-multiple-columns\n",
    "for feature in weeks_list:\n",
    "    data[feature] = pd.cut(x=data[feature], bins=[0,20,40,128], labels=[1,2,3]) #discrete values    \n",
    "\n",
    "#customized binning for the following features    \n",
    "\n",
    "#data['Age '] = pd.cut(x=data['Age '], bins=[0,32,37,42,47,52,57,62], labels=[1,2,3,4,5,6,7])\n",
    "data['BMI'] = pd.cut(x=data['BMI'], bins=[0,18.5,25,30,35,40], labels=[1,2,3,4,5])\n",
    "data['WBC'] = pd.cut(x=data['WBC'], bins=[0,4000,11000,12101], labels=[1,2,3])\n",
    "data['RBC'] = pd.cut(x=data['RBC'], bins=[0,3000000,5000000,5018451], labels=[1,2,3])\n",
    "#data['Plat'] = pd.cut(x=data['Plat'], bins=[93013,100000,226465], labels=[1,2]) #removed a typo discrete value of 255000\n",
    "data['RNA Base'] = pd.cut(x=data['RNA Base'], bins=[0,5,1201086], labels=[1,2])                                        \n",
    "data['RNA 4'] = pd.cut(x=data['RNA 4'], bins=[0,5,1201715], labels=[1,2])    \n",
    "data['RNA 12'] = pd.cut(x=data['RNA 12'], bins=[0,5,3731527], labels=[1,2])    \n",
    "data['RNA EOT'] = pd.cut(x=data['RNA EOT'], bins=[0,5,808450], labels=[1,2])    \n",
    "data['RNA EF'] = pd.cut(x=data['RNA EF'], bins=[0,5,810333], labels=[1,2])    # corrected maximum from 808450 in discretization description\n",
    "\n",
    "# conditional binning for HGB by Gender. Each gender row is placed in a gender conditional dataframe\n",
    "male_df = data[data['Gender']==1]\n",
    "male_df['HGB'] = pd.cut(x=male_df['HGB'], bins=[2,14,17.5,20], labels=[1,2,3])\n",
    "#print(male_df)\n",
    "female_df = data[data['Gender']==2]\n",
    "female_df['HGB'] = pd.cut(x=female_df['HGB'], bins=[2,12.3,15.3,20], labels=[1,2,3])\n",
    "#print(female_df)\n",
    "#merges male and female selections into a new dataframe\n",
    "data = pd.merge(male_df, female_df, how='outer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Age   Gender  BMI  Fever  Nausea/Vomting  Headache   Diarrhea   \\\n",
      "0      45       1    3      2               1          2          2   \n",
      "1      34       1    2      1               2          1          1   \n",
      "2      58       1    4      2               1          1          1   \n",
      "3      61       1    4      1               2          2          2   \n",
      "4      56       1    3      1               2          2          2   \n",
      "..    ...     ...  ...    ...             ...        ...        ...   \n",
      "850    59       2    4      2               2          2          1   \n",
      "851    43       2    2      1               2          2          1   \n",
      "852    36       2    4      1               2          2          1   \n",
      "853    47       2    4      2               2          2          2   \n",
      "854    52       2    2      1               2          1          1   \n",
      "\n",
      "     Fatigue & generalized bone ache   Jaundice   Epigastric pain   ...  \\\n",
      "0                                   1          1                 2  ...   \n",
      "1                                   2          2                 1  ...   \n",
      "2                                   2          1                 1  ...   \n",
      "3                                   1          1                 2  ...   \n",
      "4                                   2          2                 2  ...   \n",
      "..                                ...        ...               ...  ...   \n",
      "850                                 2          1                 2  ...   \n",
      "851                                 1          2                 2  ...   \n",
      "852                                 2          1                 2  ...   \n",
      "853                                 1          1                 2  ...   \n",
      "854                                 1          1                 1  ...   \n",
      "\n",
      "     ALT 24  ALT 36  ALT 48  ALT after 24 w  RNA Base  RNA 4  RNA 12  RNA EOT  \\\n",
      "0         3       3       3               2         2      2       2        2   \n",
      "1         3       3       3               2         2      2       2        2   \n",
      "2         3       3       3               2         2      2       2        2   \n",
      "3         3       3       3               2         2      2       1        1   \n",
      "4         3       3       3               2         2      2       2        2   \n",
      "..      ...     ...     ...             ...       ...    ...     ...      ...   \n",
      "850       3       3       3               2         2      2       2        2   \n",
      "851       3       3       3               2         2      2       2        2   \n",
      "852       3       3       3               2         2      2       1        1   \n",
      "853       3       3       3               3         2      2       1        1   \n",
      "854       3       3       3               3         2      2       2        2   \n",
      "\n",
      "     RNA EF  Baselinehistological staging  \n",
      "0         2                             2  \n",
      "1         2                             2  \n",
      "2         2                             1  \n",
      "3         1                             4  \n",
      "4         2                             4  \n",
      "..      ...                           ...  \n",
      "850       2                             4  \n",
      "851       2                             3  \n",
      "852       1                             1  \n",
      "853       1                             3  \n",
      "854       2                             2  \n",
      "\n",
      "[855 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "# converting all datatypes to float because most are of a 'category' type (Robert)\n",
    "# source: https://stackoverflow.com/questions/44369504/how-to-convert-entire-dataframe-values-to-float-in-pandas\n",
    "data = data.apply(pd.to_numeric, errors='coerce')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "#seperate X and y\n",
    "X = data.iloc[:,:-1]\n",
    "y = data.iloc[:,-1]\n",
    "\n",
    "#Calculate biomarker scores\n",
    "fib4 = (X['Age ']*X['AST 1'])/(X['Plat']*np.sqrt(X['ALT 1']))\n",
    "modapri = (X['Age ']*X['AST 1'])/(X['Plat']*100)\n",
    "liverDam = X['AST 1']/X['ALT 1']\n",
    "\n",
    "''' \n",
    "#Feature selection Age, Gender, BMI  # These are not enough features in this scope, so removing it (Robert)\n",
    "ModX = X.iloc[:,0:3]\n",
    "'''\n",
    "ModX = X.iloc[:,:-1]\n",
    "\n",
    "#Select ALT scores over time\n",
    "ModX['ALT 1'] = X['ALT 1']\n",
    "ModX['ALT4'] = X['ALT4']\n",
    "ModX['ALT 24'] = X['ALT 24']\n",
    "ModX['ALT 48'] = X['ALT 48']\n",
    "\n",
    "ModX['AST 1'] = X['AST 1']\n",
    "\n",
    "ModX['fib4'] = fib4\n",
    "ModX['modapri'] = modapri\n",
    "ModX['liverDam'] = liverDam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    1\n",
      "3    0\n",
      "4    0\n",
      "Name: Baselinehistological staging, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:205: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    }
   ],
   "source": [
    "#Transform y to only focus on F4 (Alexander) ## Binary targeting (Robert)\n",
    "\n",
    "for i in range(len(y)):\n",
    "    current = y.iloc[i]\n",
    "    if current != 1:\n",
    "        y.iloc[i] = 0\n",
    "        \n",
    "print(y.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Age   Gender  BMI  Fever  Nausea/Vomting  Headache   Diarrhea   \\\n",
      "0    45       1    3      2               1          2          2   \n",
      "1    34       1    2      1               2          1          1   \n",
      "2    58       1    4      2               1          1          1   \n",
      "3    61       1    4      1               2          2          2   \n",
      "4    56       1    3      1               2          2          2   \n",
      "\n",
      "   Fatigue & generalized bone ache   Jaundice   Epigastric pain   ...  ALT 36  \\\n",
      "0                                 1          1                 2  ...       3   \n",
      "1                                 2          2                 1  ...       3   \n",
      "2                                 2          1                 1  ...       3   \n",
      "3                                 1          1                 2  ...       3   \n",
      "4                                 2          2                 2  ...       3   \n",
      "\n",
      "   ALT 48  ALT after 24 w  RNA Base  RNA 4  RNA 12  RNA EOT  fib4  modapri  \\\n",
      "0       3               2         2      2       2        2   0.0      0.0   \n",
      "1       3               2         2      2       2        2   0.0      0.0   \n",
      "2       3               2         2      2       2        2   0.0      0.0   \n",
      "3       3               2         2      2       1        1   0.0      0.0   \n",
      "4       3               2         2      2       2        2   0.0      0.0   \n",
      "\n",
      "   liverDam  \n",
      "0       1.0  \n",
      "1       1.0  \n",
      "2       1.0  \n",
      "3       1.0  \n",
      "4       1.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "##--- Descritization found in literature (Alexander) \n",
    "#Apply discretization to calculated ratios\n",
    "\n",
    "#Modify apri ratio\n",
    "for i in range(len(X)):\n",
    "    current = ModX.iloc[i,-2]\n",
    "    if current > 0.5 :   # literature says 0.7,  mathematical model says 0.5 (Selina)\n",
    "        ModX.iloc[i,-2] = 1\n",
    "    else:\n",
    "        ModX.iloc[i,-2] = 0\n",
    "\n",
    "#Modify liverdam ratio\n",
    "for i in range(len(X)):\n",
    "    current = ModX.iloc[i,-1]\n",
    "    if current >= 1 :\n",
    "        ModX.iloc[i,-1] = 1\n",
    "    else:\n",
    "        ModX.iloc[i,-1] = 0\n",
    "\n",
    "#Modify fib4  ratio\n",
    "for i in range(len(X)):\n",
    "    current = ModX.iloc[i,-3]\n",
    "    if current < 1.45 :\n",
    "        ModX.iloc[i,-3] = 0\n",
    "    else:\n",
    "        ModX.iloc[i,-3] = 1\n",
    "        \n",
    "print(ModX.head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training and test data # switching from 0.2 to 0.5 test size (Robert)\n",
    "X_train, X_test, y_train, y_test = train_test_split(ModX, y, test_size = 0.60, random_state = 0) \n",
    "\n",
    "#Feature scale so that one feature doesn't have more influence than another\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.18082818,  0.9883717 ,  0.02168284, ...,  0.        ,\n",
       "         0.        ,  0.10878566],\n",
       "       [ 1.11001741,  0.9883717 , -1.21423929, ...,  0.        ,\n",
       "         0.        ,  0.10878566],\n",
       "       [ 0.52326941,  0.9883717 ,  0.02168284, ...,  0.        ,\n",
       "         0.        ,  0.10878566],\n",
       "       ...,\n",
       "       [ 0.87531821,  0.9883717 ,  1.25760498, ...,  0.        ,\n",
       "         0.        ,  0.10878566],\n",
       "       [-1.70637297,  0.9883717 , -1.21423929, ...,  0.        ,\n",
       "         0.        ,  0.10878566],\n",
       "       [-0.41552738,  0.9883717 ,  0.02168284, ...,  0.        ,\n",
       "         0.        ,  0.10878566]])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.64285714 0.63235294 0.67647059 0.63235294 0.63235294]\n",
      "0.6432773109243697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n",
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Use Bayesian Optimization?\n",
    "#Here we are going to make a simple SVM classifier\n",
    "classifier = svm.NuSVC(nu = 0.3, kernel='rbf')\n",
    "#Carry out cross validation 10 fold and find the mean of the score to get overall accuracy for train data\n",
    "scores = cross_val_score(classifier, X_train, y_train, cv=5) # set 'cv' to 5 to increase sample size\n",
    "print(scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9649122807017544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "#train the classifier on train set and then print out its overall accuracy for the train data\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "print(classifier.score(X_train,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6432748538011696\n"
     ]
    }
   ],
   "source": [
    "#Determine the overall accuracy score of the test data set\n",
    "print(classifier.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      "[[306  79]\n",
      " [104  24]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.79      0.77       385\n",
      "           1       0.23      0.19      0.21       128\n",
      "\n",
      "    accuracy                           0.64       513\n",
      "   macro avg       0.49      0.49      0.49       513\n",
      "weighted avg       0.62      0.64      0.63       513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Making predictions\n",
    "y_pred = classifier.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The confusion matrix is:\n",
      "[[367  18]\n",
      " [125   3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.95      0.84       385\n",
      "           1       0.14      0.02      0.04       128\n",
      "\n",
      "    accuracy                           0.72       513\n",
      "   macro avg       0.44      0.49      0.44       513\n",
      "weighted avg       0.60      0.72      0.64       513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Training with k-nearest neighbor (KNN)\n",
    "classifier2 = KNeighborsClassifier(n_neighbors = 4 )\n",
    "classifier2.fit(X_train, y_train)\n",
    "#Making predictions\n",
    "y_pred = classifier2.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.6237816764132553\n",
      "The confusion matrix is:\n",
      "[[291  94]\n",
      " [ 99  29]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.76      0.75       385\n",
      "           1       0.24      0.23      0.23       128\n",
      "\n",
      "    accuracy                           0.62       513\n",
      "   macro avg       0.49      0.49      0.49       513\n",
      "weighted avg       0.62      0.62      0.62       513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Decision trees\n",
    "#Here we are going to make a simple decision classifier\n",
    "clf = tree.DecisionTreeClassifier()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(clf.score(X_train,y_train))\n",
    "#Determine the overall accuracy score of the test data set\n",
    "print(clf.score(X_test,y_test))\n",
    "#Making predictions\n",
    "y_pred = clf.predict(X_test)\n",
    "#To evaluate algorithm we will print the confusion matrix and other metrics\n",
    "print(\"The confusion matrix is:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
